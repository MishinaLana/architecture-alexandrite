# ЛОГИ

Все компоненты требуют покрытия логами.
Логи. Уровень INFO:

1. Изменение статуса заказа:
- Время
- ID заказа
- ID пользователя
- Исходный статус
- Новый статус

2. Расчет стоимости заказа:
- ID заказа
- Время выполнения
- Количество полигонов в модели

3. Загрузка 3D-файла:
- ID пользователя
- ID заказа
- Размер файла
- Имя файла

4. Отправка/получение сообщений через RabbitMQ:
- ID сообщения
- Тип события
- ID заказа

5. Ошибки валидации заказа:
- ID заказа
- Код ошибки

6. Вход пользователя в систему:
- ID пользователя
- Время
- Роль

7. Запросы к API:
- endpoint
- HTTP-метод
- Статус ответа
- Время выполнения

ERROR: Критические ошибки (падение сервиса, ошибки расчёта стоимости)
WARN: Подозрительные действия (повторная отправка сообщения, некорректный статус заказа)
DEBUG: Детальная отладка (содержимое запросов к БД, промежуточные этапы расчёта стоимости).



#МОТИВАЦИЯ

Для чего нужно логирование:
- Ускорить поиск причины или факта инцидентов на объективных данных
- Снизить нагрузку на поддержку за счет автоматического сбора контекста ошибок
- Улучшить мониторинг производительности системы

Технические метрики:
- Время отклика ключевых API
- Количество ошибок 5xx/4xx в единицу времени
- Задержки в обработке сообщений RabbitMQ

Бизнес-метрики:
- Среднее время выполнения заказа
- Количество успешно завершенных или отмененных заказов
- Удовлетворённость клиентов (сокращение числа жалоб).

Приоритеты внедрения:
1. MES API и CRM API - центральные компоненты для расчета стоимости и управления заказами
2. RabbitMQ - критичная интеграция между системами
3. Internet Shop - точка входа клиентов


#ПРЕДЛАГАЕМОЕ РЕШЕНИЕ

Технологии:
- ELK-стек (Elasticsearch, Logstash, Kibana) для сбора, обработки и визуализации логов
- Filebeat на каждом сервере для отправки логов в Logstash
- RabbitMQ plugin для Logstash для логирования сообщений

Доработки:
- Добавить в каждый сервис единый формат логов (timestamp, service_name, log_level, message, context)
- Настроить Filebeat для передачи логов в Logstash

Безопасность:
- Чувствительные данные (номера карт, персональные данные) маскируются в логах через Logstash-фильтры
- Доступ к Kibana только для DevOps, разработчиков и QA
- Логи шифруются при передаче (TLS) и хранении

Хранение:
- Отдельный индекс в Elasticsearch для каждого сервиса.

Срок хранения:
Логи приложений: 30 дней
Размер: ~50 ГБ в день для всех сервисов


#МЕРОПРИЯТИЯ

Настроить оповещения в Kibana/Slack при:
- Резком росте ошибок 5xx >10% от числа запросов
- Задержке расчета стоимости >30 минут
- Недоступности ключевых сервисов API

Поиск аномалий:
- Использовать Machine Learning в Elasticsearch для обнаружения аномалий (DDoS-атака по количеству заказов в секунду)
- Настроить дашборды в Kibana для отслеживания:
    Количество заказов в статусе расчет стоимости больше 10 минут
    Сообщения в RabbitMQ со статусом необработано

